
@article{arandjelovic_objects_2018,
	title = {Objects that {Sound}},
	shorttitle = {Objects that {Sound}},
	url = {http://arxiv.org/abs/1712.06651},
	abstract = {In this paper our objectives are, ﬁrst, networks that can embed audio and visual inputs into a common space that is suitable for cross-modal retrieval; and second, a network that can localize the object that sounds in an image, given the audio signal. We achieve both these objectives by training from unlabelled video using only audio-visual correspondence (AVC) as the objective function. This is a form of crossmodal self-supervision from video.},
	language = {en},
	urldate = {2020-12-02},
	journal = {arXiv:1712.06651 [cs, eess]},
	author = {Arandjelović, Relja and Zisserman, Andrew},
	month = jul,
	year = {2018},
	note = {arXiv: 1712.06651},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Multimedia, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	}

@inproceedings{ismail_fawaz_deep_2019,
	address = {Budapest, Hungary},
	title = {Deep {Neural} {Network} {Ensembles} for {Time} {Series} {Classification}},
	isbn = {978-1-72811-985-4},
	url = {https://ieeexplore.ieee.org/document/8852316/},
	doi = {10.1109/IJCNN.2019.8852316},
	abstract = {Deep neural networks have revolutionized many ﬁelds such as computer vision and natural language processing. Inspired by this recent success, deep learning started to show promising results for Time Series Classiﬁcation (TSC). However, neural networks are still behind the state-of-the-art TSC algorithms, that are currently composed of ensembles of 37 non deep learning based classiﬁers. We attribute this gap in performance due to the lack of neural network ensembles for TSC. Therefore in this paper, we show how an ensemble of 60 deep learning models can signiﬁcantly improve upon the current state-of-the-art performance of neural networks for TSC, when evaluated over the UCR/UEA archive: the largest publicly available benchmark for time series analysis. Finally, we show how our proposed Neural Network Ensemble (NNE) is the ﬁrst time series classiﬁer to outperform COTE while reaching similar performance to the current state-of-the-art ensemble HIVE-COTE.},
	language = {en},
	urldate = {2022-11-06},
	booktitle = {2019 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = jul,
	year = {2019},
	pages = {1--6},
	}

@article{breiman_bagging_1996,
	title = {Bagging predictors},
	volume = {24},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00058655},
	doi = {10.1007/BF00058655},
	abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.},
	language = {en},
	number = {2},
	urldate = {2022-11-23},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = aug,
	year = {1996},
	keywords = {Aggregation, Averaging, Bootstrap, Combining},
	pages = {123--140},
	}

@article{wen_ensemble_2017,
	title = {Ensemble of {Deep} {Neural} {Networks} with {Probability}-{Based} {Fusion} for {Facial} {Expression} {Recognition}},
	volume = {9},
	issn = {1866-9964},
	url = {https://doi.org/10.1007/s12559-017-9472-6},
	doi = {10.1007/s12559-017-9472-6},
	abstract = {Convolutional neural network (CNN) is a very effective method to recognize facial emotions. However, the preprocessing and selection of parameters of these methods heavily depend on the human experience and require a large amount of trial-and-errors. This paper presents an ensemble of convolutional neural networks method with probability-based fusion for facial expression recognition, where the architecture of CNN was adapted by using the convolutional rectified linear layer as the first layer and multiple hidden maxout layers. It was constructed by randomly varying parameters and architecture around the optimal values for CNN, where each CNN as the base classifier was trained to output a probability for each class. These probabilities were then fused through the probability-based fusion method. The conducted experiments on benchmark data sets validated our method, which had better accuracy than the compared methods. The proposed method was novel and efficient for facial expression recognition.},
	language = {en},
	number = {5},
	urldate = {2022-11-21},
	journal = {Cognitive Computation},
	author = {Wen, Guihua and Hou, Zhi and Li, Huihui and Li, Danyang and Jiang, Lijun and Xun, Eryang},
	month = oct,
	year = {2017},
	keywords = {Convolutional neural network, Deep learning, Ensemble learning, Facial expression recognition, Probability-based fusion},
	pages = {597--610},
	}

@misc{goyal_deep_2018,
	title = {Deep neural network ensemble by data augmentation and bagging for skin lesion classification},
	url = {http://arxiv.org/abs/1807.05496},
	doi = {10.48550/arXiv.1807.05496},
	abstract = {This work summarizes our submission for the Task 3: Disease Classification of ISIC 2018 challenge in Skin Lesion Analysis Towards Melanoma Detection. We use a novel deep neural network (DNN) ensemble architecture introduced by us that can effectively classify skin lesions by using data-augmentation and bagging to address paucity of data and prevent over-fitting. The ensemble is composed of two DNN architectures: Inception-v4 and Inception-Resnet-v2. The DNN architectures are combined in to an ensemble by using a \$1{\textbackslash}times1\$ convolution for fusion in a meta-learning layer.},
	urldate = {2022-11-21},
	publisher = {arXiv},
	author = {Goyal, Manik and Rajapakse, Jagath C.},
	month = jul,
	year = {2018},
	note = {arXiv:1807.05496 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	}

@incollection{kwok_multiple_1990,
	series = {Uncertainty in {Artificial} {Intelligence}},
	title = {Multiple decision trees},
	volume = {9},
	url = {https://www.sciencedirect.com/science/article/pii/B9780444886507500305},
	abstract = {This paper describes experiments, on two domains, to investigate the effect of averaging over predictions of multiple decision trees, instead of using a single tree. Other authors have pointed out theoretical and commonsense reasons for preferring the multiple tree approach. Ideally, we would like to consider predictions from all trees, weighted by their probability. However, there is a vast number of different trees, and it is difficult to estimate the probability of each tree. We sidestep the estimation problem by using a modified version of the ID3 algorithm to build good trees, and average over only these trees. Our results are encouraging. For each domain, we managed to produce a small number of good trees. We find that it is best to average across sets of trees with different structure; this usually gives better performance than any of the constituent trees, including the ID3 tree. Keywords: machine learning, transduction, empirical evaluation},
	language = {en},
	urldate = {2022-11-23},
	booktitle = {Machine {Intelligence} and {Pattern} {Recognition}},
	publisher = {North-Holland},
	author = {Kwok, Suk Wah and Carter, Chris},
	editor = {Shachter, Ross D. and Levitt, Tod S. and Kanal, Laveen N. and Lemmer, John F.},
	month = jan,
	year = {1990},
	doi = {10.1016/B978-0-444-88650-7.50030-5},
	pages = {327--335},
	}

@inproceedings{choromanska_loss_2015,
	title = {The {Loss} {Surfaces} of {Multilayer} {Networks}},
	url = {https://proceedings.mlr.press/v38/choromanska15.html},
	abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
	language = {en},
	urldate = {2022-11-23},
	booktitle = {Proceedings of the {Eighteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Choromanska, Anna and Henaff, MIkael and Mathieu, Michael and Arous, Gerard Ben and LeCun, Yann},
	month = feb,
	year = {2015},
	note = {ISSN: 1938-7228},
	pages = {192--204},
	}

@article{hansen_neural_1990,
	title = {Neural network ensembles},
	volume = {12},
	issn = {1939-3539},
	doi = {10.1109/34.58871},
	abstract = {Several means for improving the performance and training of neural networks for classification are proposed. Crossvalidation is used as a tool for optimizing network parameters and architecture. It is shown that the remaining residual generalization error can be reduced by invoking ensembles of similar networks.{\textless}{\textgreater}},
	number = {10},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Hansen, L.K. and Salamon, P.},
	month = oct,
	year = {1990},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Computer architecture, Data mining, Databases, Fault tolerance, Feedforward systems, Neural networks, Neurons, Pattern recognition, Performance analysis, Supervised learning},
	pages = {993--1001},
	}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2023-03-19},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	language = {en},
	number = {7540},
	urldate = {2023-05-08},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	pages = {529--533},
	}

@misc{mnih_playing_2013,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	urldate = {2023-05-08},
	publisher = {arXiv},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	month = dec,
	year = {2013},
	note = {arXiv:1312.5602 [cs]},
	keywords = {Computer Science - Machine Learning},
	}

@misc{wortsman_model_2022,
	title = {Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
	shorttitle = {Model soups},
	url = {http://arxiv.org/abs/2203.05482},
	doi = {10.48550/arXiv.2203.05482},
	abstract = {The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set, discarding the remainder. In this paper, we revisit the second step of this procedure in the context of fine-tuning large pre-trained models, where fine-tuned models often appear to lie in a single low error basin. We show that averaging the weights of multiple models fine-tuned with different hyperparameter configurations often improves accuracy and robustness. Unlike a conventional ensemble, we may average many models without incurring any additional inference or memory costs -- we call the results "model soups." When fine-tuning large pre-trained models such as CLIP, ALIGN, and a ViT-G pre-trained on JFT, our soup recipe provides significant improvements over the best model in a hyperparameter sweep on ImageNet. The resulting ViT-G model, which attains 90.94\% top-1 accuracy on ImageNet, achieved a new state of the art. Furthermore, we show that the model soup approach extends to multiple image classification and natural language processing tasks, improves out-of-distribution performance, and improves zero-shot performance on new downstream tasks. Finally, we analytically relate the performance similarity of weight-averaging and logit-ensembling to flatness of the loss and confidence of the predictions, and validate this relation empirically. Code is available at https://github.com/mlfoundations/model-soups.},
	urldate = {2023-08-16},
	publisher = {arXiv},
	author = {Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Yitzhak and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S. and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and Schmidt, Ludwig},
	month = jul,
	year = {2022},
	note = {arXiv:2203.05482 [cs]
version: 3},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	}

@misc{huang_snapshot_2017,
	title = {Snapshot {Ensembles}: {Train} 1, get {M} for free},
	shorttitle = {Snapshot {Ensembles}},
	url = {http://arxiv.org/abs/1704.00109},
	doi = {10.48550/arXiv.1704.00109},
	abstract = {Ensembles of neural networks are known to be much more robust and accurate than individual networks. However, training multiple deep networks for model averaging is computationally expensive. In this paper, we propose a method to obtain the seemingly contradictory goal of ensembling multiple neural networks at no additional training cost. We achieve this goal by training a single neural network, converging to several local minima along its optimization path and saving the model parameters. To obtain repeated rapid convergence, we leverage recent work on cyclic learning rate schedules. The resulting technique, which we refer to as Snapshot Ensembling, is simple, yet surprisingly effective. We show in a series of experiments that our approach is compatible with diverse network architectures and learning tasks. It consistently yields lower error rates than state-of-the-art single models at no additional training cost, and compares favorably with traditional network ensembles. On CIFAR-10 and CIFAR-100 our DenseNet Snapshot Ensembles obtain error rates of 3.4\% and 17.4\% respectively.},
	urldate = {2023-08-16},
	publisher = {arXiv},
	author = {Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E. and Weinberger, Kilian Q.},
	month = mar,
	year = {2017},
	note = {arXiv:1704.00109 [cs]},
	keywords = {Computer Science - Machine Learning},
	}

@misc{van_hasselt_deep_2015,
	title = {Deep {Reinforcement} {Learning} with {Double} {Q}-learning},
	url = {http://arxiv.org/abs/1509.06461},
	abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions afﬁrmatively. In particular, we ﬁrst show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a speciﬁc adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
	language = {en},
	urldate = {2023-09-02},
	publisher = {arXiv},
	author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
	month = dec,
	year = {2015},
	note = {arXiv:1509.06461 [cs]},
	keywords = {Computer Science - Machine Learning},
	}

@inproceedings{lee_sunrise_2021,
	title = {{SUNRISE}: {A} {Simple} {Unified} {Framework} for {Ensemble} {Learning} in {Deep} {Reinforcement} {Learning}},
	shorttitle = {{SUNRISE}},
	url = {https://proceedings.mlr.press/v139/lee21g.html},
	abstract = {Off-policy deep reinforcement learning (RL) has been successful in a range of challenging domains. However, standard off-policy RL algorithms can suffer from several issues, such as instability in Q-learning and balancing exploration and exploitation. To mitigate these issues, we present SUNRISE, a simple unified ensemble method, which is compatible with various off-policy RL algorithms. SUNRISE integrates two key ingredients: (a) ensemble-based weighted Bellman backups, which re-weight target Q-values based on uncertainty estimates from a Q-ensemble, and (b) an inference method that selects actions using the highest upper-confidence bounds for efficient exploration. By enforcing the diversity between agents using Bootstrap with random initialization, we show that these different ideas are largely orthogonal and can be fruitfully integrated, together further improving the performance of existing off-policy RL algorithms, such as Soft Actor-Critic and Rainbow DQN, for both continuous and discrete control tasks on both low-dimensional and high-dimensional environments.},
	language = {en},
	urldate = {2023-09-23},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Lee, Kimin and Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {6131--6141},
	}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	urldate = {2023-09-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year = {2012},
	}

@article{littlestone_weighted_1994,
	title = {The {Weighted} {Majority} {Algorithm}},
	volume = {108},
	issn = {0890-5401},
	url = {https://www.sciencedirect.com/science/article/pii/S0890540184710091},
	doi = {10.1006/inco.1994.1009},
	abstract = {We study the construction of prediction algorithms in a situation in which a learner faces a sequence of trials, with a prediction to be made in each, and the goal of the learner is to make few mistakes. We are interested in the case where the learner has reason to believe that one of some pool of known algorithms will perform well, but the learner does not know which one. A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in such a circumstance. We call this method the Weighted Majority Algorithm. We show that this algorithm is robust in the presence of errors in the data. We discuss various versions of the Weighted Majority Algorithm and prove mistake bounds for them that are closely related to the mistake bounds of the best algorithms of the pool. For example, given a sequence of trials, if there is an algorithm in the pool A that makes at most m mistakes then the Weighted Majority Algorithm will make at most c(log {\textbar}A{\textbar} + m) mistakes on that sequence, where c is fixed constant.},
	number = {2},
	urldate = {2023-09-26},
	journal = {Information and Computation},
	author = {Littlestone, N. and Warmuth, M. K.},
	month = feb,
	year = {1994},
	pages = {212--261},
	}

@article{hahnloser_digital_2000,
	title = {Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit},
	volume = {405},
	copyright = {2000 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/35016072},
	doi = {10.1038/35016072},
	abstract = {Digital circuits such as the flip-flop use feedback to achieve multi-stability and nonlinearity to restore signals to logical levels, for example 0 and 1. Analogue feedback circuits are generally designed to operate linearly, so that signals are over a range, and the response is unique. By contrast, the response of cortical circuits to sensory stimulation can be both multistable and graded1,2,3,4. We propose that the neocortex combines digital selection of an active set of neurons with analogue response by dynamically varying the positive feedback inherent in its recurrent connections. Strong positive feedback causes differential instabilities that drive the selection of a set of active neurons under the constraints embedded in the synaptic weights. Once selected, the active neurons generate weaker, stable feedback that provides analogue amplification of the input. Here we present our model of cortical processing as an electronic circuit that emulates this hybrid operation, and so is able to perform computations that are similar to stimulus selection, gain modulation and spatiotemporal pattern generation in the neocortex.},
	language = {en},
	number = {6789},
	urldate = {2023-09-26},
	journal = {Nature},
	author = {Hahnloser, Richard H. R. and Sarpeshkar, Rahul and Mahowald, Misha A. and Douglas, Rodney J. and Seung, H. Sebastian},
	month = jun,
	year = {2000},
	note = {Number: 6789
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {947--951},
	}

@article{huber_robust_1964,
	title = {Robust {Estimation} of a {Location} {Parameter}},
	volume = {35},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-35/issue-1/Robust-Estimation-of-a-Location-Parameter/10.1214/aoms/1177703732.full},
	doi = {10.1214/aoms/1177703732},
	abstract = {This paper contains a new approach toward a theory of robust estimation; it treats in detail the asymptotic theory of estimating a location parameter for contaminated normal distributions, and exhibits estimators--intermediaries between sample mean and sample median--that are asymptotically most robust (in a sense to be specified) among all translation invariant estimators. For the general background, see Tukey (1960) (p. 448 ff.) Let \$x\_1, {\textbackslash}cdots, x\_n\$ be independent random variables with common distribution function \$F(t - {\textbackslash}xi)\$. The problem is to estimate the location parameter \${\textbackslash}xi\$, but with the complication that the prototype distribution \$F(t)\$ is only approximately known. I shall primarily be concerned with the model of indeterminacy \$F = (1 - {\textbackslash}epsilon){\textbackslash}Phi + {\textbackslash}epsilon H\$, where \$0 {\textbackslash}leqq {\textbackslash}epsilon {\textless} 1\$ is a known number, \${\textbackslash}Phi(t) = (2{\textbackslash}pi){\textasciicircum}\{-{\textbackslash}frac\{1\}\{2\}\} {\textbackslash}int{\textasciicircum}t\_\{-{\textbackslash}infty\} {\textbackslash}exp(-{\textbackslash}frac\{1\}\{2\}s{\textasciicircum}2) ds\$ is the standard normal cumulative and \$H\$ is an unknown contaminating distribution. This model arises for instance if the observations are assumed to be normal with variance 1, but a fraction \${\textbackslash}epsilon\$ of them is affected by gross errors. Later on, I shall also consider other models of indeterminacy, e.g., \${\textbackslash}sup\_t {\textbar}F(t) - {\textbackslash}Phi(t){\textbar} {\textbackslash}leqq {\textbackslash}epsilon\$. Some inconvenience is caused by the fact that location and scale parameters are not uniquely determined: in general, for fixed \${\textbackslash}epsilon\$, there will be several values of \${\textbackslash}xi\$ and \${\textbackslash}sigma\$ such that \${\textbackslash}sup\_t{\textbar}F(t) - {\textbackslash}Phi((t - {\textbackslash}xi)/{\textbackslash}sigma){\textbar} {\textbackslash}leqq {\textbackslash}epsilon\$, and similarly for the contaminated case. Although this inherent and unavoidable indeterminacy is small if \${\textbackslash}epsilon\$ is small and is rather irrelevant for practical purposes, it poses awkward problems for the theory, especially for optimality questions. To remove this difficulty, one may either (i) restrict attention to symmetric distributions, and estimate the location of the center of symmetry (this works for \${\textbackslash}xi\$ but not for \${\textbackslash}sigma\$); or (ii) one may define the parameter to be estimated in terms of the estimator itself, namely by its asymptotic value for sample size \$n {\textbackslash}rightarrow {\textbackslash}infty\$; or (iii) one may define the parameters by arbitrarily chosen functionals of the distribution (e.g., by the expectation, or the median of \$F\$). All three possibilities have unsatisfactory aspects, and I shall usually choose the variant which is mathematically most convenient. It is interesting to look back to the very origin of the theory of estimation, namely to Gauss and his theory of least squares. Gauss was fully aware that his main reason for assuming an underlying normal distribution and a quadratic loss function was mathematical, i.e., computational, convenience. In later times, this was often forgotten, partly because of the central limit theorem. However, if one wants to be honest, the central limit theorem can at most explain why many distributions occurring in practice are approximately normal. The stress is on the word "approximately." This raises a question which could have been asked already by Gauss, but which was, as far as I know, only raised a few years ago (notably by Tukey): What happens if the true distribution deviates slightly from the assumed normal one? As is now well known, the sample mean then may have a catastrophically bad performance: seemingly quite mild deviations may already explode its variance. Tukey and others proposed several more robust substitutes--trimmed means, Winsorized means, etc.--and explored their performance for a few typical violations of normality. A general theory of robust estimation is still lacking; it is hoped that the present paper will furnish the first few steps toward such a theory. At the core of the method of least squares lies the idea to minimize the sum of the squared "errors," that is, to adjust the unknown parameters such that the sum of the squares of the differences between observed and computed values is minimized. In the simplest case, with which we are concerned here, namely the estimation of a location parameter, one has to minimize the expression \${\textbackslash}sum\_i (x\_i - T){\textasciicircum}2\$; this is of course achieved by the sample mean \$T = {\textbackslash}sum\_i x\_i/n\$. I should like to emphasize that no loss function is involved here; I am only describing how the least squares estimator is defined, and neither the underlying family of distributions nor the true value of the parameter to be estimated enters so far. It is quite natural to ask whether one can obtain more robustness by minimizing another function of the errors than the sum of their squares. We shall therefore concentrate our attention to estimators that can be defined by a minimum principle of the form (for a location parameter): \$T = T\_n(x\_1, {\textbackslash}cdots, x\_n) minimizes {\textbackslash}sum\_i {\textbackslash}rho(x\_i - T),\$ {\textbackslash}begin\{equation*\} {\textbackslash}tag\{M\} where {\textbackslash}rho is a non-constant function. {\textbackslash}end\{equation*\} Of course, this definition generalizes at once to more general least squares type problems, where several parameters have to be determined. This class of estimators contains in particular (i) the sample mean \$({\textbackslash}rho(t) = t{\textasciicircum}2)\$, (ii) the sample median \$({\textbackslash}rho(t) = {\textbar}t{\textbar})\$, and more generally, (iii) all maximum likelihood estimators \$({\textbackslash}rho(t) = -{\textbackslash}log f(t)\$, where \$f\$ is the assumed density of the untranslated distribution). These (\$M\$)-estimators, as I shall call them for short, have rather pleasant asymptotic properties; sufficient conditions for asymptotic normality and an explicit expression for their asymptotic variance will be given. How should one judge the robustness of an estimator \$T\_n(x) = T\_n(x\_1, {\textbackslash}cdots, x\_n)\$? Since ill effects from contamination are mainly felt for large sample sizes, it seems that one should primarily optimize large sample robustness properties. Therefore, a convenient measure of robustness for asymptotically normal estimators seems to be the supremum of the asymptotic variance \$(n {\textbackslash}rightarrow {\textbackslash}infty)\$ when \$F\$ ranges over some suitable set of underlying distributions, in particular over the set of all \$F = (1 - {\textbackslash}epsilon){\textbackslash}Phi + {\textbackslash}epsilon H\$ for fixed \${\textbackslash}epsilon\$ and symmetric \$H\$. On second thought, it turns out that the asymptotic variance is not only easier to handle, but that even for moderate values of \$n\$ it is a better measure of performance than the actual variance, because (i) the actual variance of an estimator depends very much on the behavior of the tails of \$H\$, and the supremum of the actual variance is infinite for any estimator whose value is always contained in the convex hull of the observations. (ii) If an estimator is asymptotically normal, then the important central part of its distribution and confidence intervals for moderate confidence levels can better be approximated in terms of the asymptotic variance than in terms of the actual variance. If we adopt this measure of robustness, and if we restrict attention to (\$M\$)-estimators, then it will be shown that the most robust estimator is uniquely determined and corresponds to the following \${\textbackslash}rho:{\textbackslash}rho(t) = {\textbackslash}frac\{1\}\{2\}t{\textasciicircum}2\$ for \${\textbar}t{\textbar} {\textless} k, {\textbackslash}rho(t) = k{\textbar}t{\textbar} - {\textbackslash}frac\{1\}\{2\}k{\textasciicircum}2\$ for \${\textbar}t{\textbar} {\textbackslash}geqq k\$, with \$k\$ depending on \${\textbackslash}epsilon\$. This estimator is most robust even among all translation invariant estimators. Sample mean \$(k = {\textbackslash}infty)\$ and sample median \$(k = 0)\$ are limiting cases corresponding to \${\textbackslash}epsilon = 0\$ and \${\textbackslash}epsilon = 1\$, respectively, and the estimator is closely related and asymptotically equivalent to Winsorizing. I recall the definition of Winsorizing: assume that the observations have been ordered, \$x\_1 {\textbackslash}leqq x\_2 {\textbackslash}leqq {\textbackslash}cdots {\textbackslash}leqq x\_n\$, then the statistic \$T = n{\textasciicircum}\{-1\}(gx\_\{g + 1\} + x\_\{g + 1\} + x\_\{g + 2\} + {\textbackslash}cdots + x\_\{n - h\} + hx\_\{n - h\})\$ is called the Winsorized mean, obtained by Winsorizing the \$g\$ leftmost and the \$h\$ rightmost observations. The above most robust (\$M\$)-estimators can be described by the same formula, except that in the first and in the last summand, the factors \$x\_\{g + 1\}\$ and \$x\_\{n - h\}\$ have to be replaced by some numbers \$u, v\$ satisfying \$x\_g {\textbackslash}leqq u {\textbackslash}leqq x\_\{g + 1\}\$ and \$x\_\{n - h\} {\textbackslash}leqq v {\textbackslash}leqq x\_\{n - h + 1\}\$, respectively; \$g, h, u\$ and \$v\$ depend on the sample. In fact, this (\$M\$)-estimator is the maximum likelihood estimator corresponding to a unique least favorable distribution \$F\_0\$ with density \$f\_0(t) = (1 - {\textbackslash}epsilon)(2{\textbackslash}pi){\textasciicircum}\{-{\textbackslash}frac\{1\}\{2\}\}e{\textasciicircum}\{-{\textbackslash}rho(t)\}\$. This \$f\_0\$ behaves like a normal density for small \$t\$, like an exponential density for large \$t\$. At least for me, this was rather surprising--I would have expected an \$f\_0\$ with much heavier tails. This result is a particular case of a more general one that can be stated roughly as follows: Assume that \$F\$ belongs to some convex set \$C\$ of distribution functions. Then the most robust (\$M\$)-estimator for the set \$C\$ coincides with the maximum likelihood estimator for the unique \$F\_0 {\textbackslash}varepsilon C\$ which has the smallest Fisher information number \$I(F) = {\textbackslash}int (f'/f){\textasciicircum}2f dt\$ among all \$F {\textbackslash}varepsilon C\$. Miscellaneous related problems will also be treated: the case of non-symmetric contaminating distributions; the most robust estimator for the model of indeterminacy \${\textbackslash}sup\_t{\textbar}F(t) - {\textbackslash}Phi(t){\textbar} {\textbackslash}leqq {\textbackslash}epsilon\$; robust estimation of a scale parameter; how to estimate location, if scale and \${\textbackslash}epsilon\$ are unknown; numerical computation of the estimators; more general estimators, e.g., minimizing \${\textbackslash}sum\_\{i {\textless} j\} {\textbackslash}rho(x\_i - T, x\_j - T)\$, where \${\textbackslash}rho\$ is a function of two arguments. Questions of small sample size theory will not be touched in this paper.},
	number = {1},
	urldate = {2023-09-26},
	journal = {The Annals of Mathematical Statistics},
	author = {Huber, Peter J.},
	month = mar,
	year = {1964},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {73--101},
	}

@article{arulkumaran_deep_2017,
	title = {Deep {Reinforcement} {Learning}: {A} {Brief} {Survey}},
	volume = {34},
	issn = {1558-0792},
	shorttitle = {Deep {Reinforcement} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/8103164},
	doi = {10.1109/MSP.2017.2743240},
	abstract = {Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.},
	number = {6},
	urldate = {2023-09-28},
	journal = {IEEE Signal Processing Magazine},
	author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	month = nov,
	year = {2017},
	note = {Conference Name: IEEE Signal Processing Magazine},
	pages = {26--38},
	}

@misc{shao_survey_2019,
	title = {A {Survey} of {Deep} {Reinforcement} {Learning} in {Video} {Games}},
	url = {http://arxiv.org/abs/1912.10944},
	abstract = {Deep reinforcement learning (DRL) has made great achievements since proposed. Generally, DRL agents receive high-dimensional inputs at each step, and make actions according to deep-neural-network-based policies. This learning mechanism updates the policy to maximize the return with an end-toend method. In this paper, we survey the progress of DRL methods, including value-based, policy gradient, and model-based algorithms, and compare their main techniques and properties. Besides, DRL plays an important role in game artiﬁcial intelligence (AI). We also take a review of the achievements of DRL in various video games, including classical Arcade games, ﬁrst-person perspective games and multi-agent real-time strategy games, from 2D to 3D, and from single-agent to multi-agent. A large number of video game AIs with DRL have achieved super-human performance, while there are still some challenges in this domain. Therefore, we also discuss some key points when applying DRL methods to this ﬁeld, including explorationexploitation, sample efﬁciency, generalization and transfer, multiagent learning, imperfect information, and delayed spare rewards, as well as some research directions.},
	language = {en},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Shao, Kun and Tang, Zhentao and Zhu, Yuanheng and Li, Nannan and Zhao, Dongbin},
	month = dec,
	year = {2019},
	note = {arXiv:1912.10944 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
	}

@inproceedings{kanakaraj_performance_2015,
	title = {Performance analysis of {Ensemble} methods on {Twitter} sentiment analysis using {NLP} techniques},
	url = {https://ieeexplore.ieee.org/document/7050801},
	doi = {10.1109/ICOSC.2015.7050801},
	abstract = {Mining opinions and analyzing sentiments from social network data help in various fields such as even prediction, analyzing overall mood of public on a particular social issue and so on. This paper involves analyzing the mood of the society on a particular news from Twitter posts. The key idea of the paper is to increase the accuracy of classification by including Natural Language Processing Techniques (NLP) especially semantics and Word Sense Disambiguation. The mined text information is subjected to Ensemble classification to analyze the sentiment. Ensemble classification involves combining the effect of various independent classifiers on a particular classification problem. Experiments conducted demonstrate that ensemble classifier outperforms traditional machine learning classifiers by 3-5\%.},
	urldate = {2023-09-28},
	booktitle = {Proceedings of the 2015 {IEEE} 9th {International} {Conference} on {Semantic} {Computing} ({IEEE} {ICSC} 2015)},
	author = {Kanakaraj, Monisha and Guddeti, Ram Mohana Reddy},
	month = feb,
	year = {2015},
	pages = {169--170},
	}

@article{maron_model_2022,
	title = {Model soups improve performance of dermoscopic skin cancer classifiers},
	volume = {173},
	issn = {0959-8049},
	url = {https://www.sciencedirect.com/science/article/pii/S0959804922004129},
	doi = {10.1016/j.ejca.2022.07.002},
	abstract = {Background
Image-based cancer classifiers suffer from a variety of problems which negatively affect their performance. For example, variation in image brightness or different cameras can already suffice to diminish performance. Ensemble solutions, where multiple model predictions are combined into one, can improve these problems. However, ensembles are computationally intensive and less transparent to practitioners than single model solutions. Constructing model soups, by averaging the weights of multiple models into a single model, could circumvent these limitations while still improving performance.
Objective
To investigate the performance of model soups for a dermoscopic melanoma-nevus skin cancer classification task with respect to (1) generalisation to images from other clinics, (2) robustness against small image changes and (3) calibration such that the confidences correspond closely to the actual predictive uncertainties.
Methods
We construct model soups by fine-tuning pre-trained models on seven different image resolutions and subsequently averaging their weights. Performance is evaluated on a multi-source dataset including holdout and external components.
Results
We find that model soups improve generalisation and calibration on the external component while maintaining performance on the holdout component. For robustness, we observe performance improvements for pertubated test images, while the performance on corrupted test images remains on par.
Conclusions
Overall, souping for skin cancer classifiers has a positive effect on generalisation, robustness and calibration. It is easy for practitioners to implement and by combining multiple models into a single model, complexity is reduced. This could be an important factor in achieving clinical applicability, as less complexity generally means more transparency.},
	urldate = {2023-09-28},
	journal = {European Journal of Cancer},
	author = {Maron, Roman C. and Hekler, Achim and Haggenmüller, Sarah and von Kalle, Christof and Utikal, Jochen S. and Müller, Verena and Gaiser, Maria and Meier, Friedegund and Hobelsberger, Sarah and Gellrich, Frank F. and Sergon, Mildred and Hauschild, Axel and French, Lars E. and Heinzerling, Lucie and Schlager, Justin G. and Ghoreschi, Kamran and Schlaak, Max and Hilke, Franz J. and Poch, Gabriela and Korsing, Sören and Berking, Carola and Heppt, Markus V. and Erdmann, Michael and Haferkamp, Sebastian and Schadendorf, Dirk and Sondermann, Wiebke and Goebeler, Matthias and Schilling, Bastian and Kather, Jakob N. and Fröhling, Stefan and Lipka, Daniel B. and Krieghoff-Henning, Eva and Brinker, Titus J.},
	month = sep,
	year = {2022},
	keywords = {Artificial intelligence, Calibration, Deep learning, Dermatology, Ensembles, Generalisation, Melanoma, Model soups, Nevus, Robustness},
	pages = {307--316},
	}

@misc{dansereau_model_2023,
	title = {Model soups to increase inference without increasing compute time},
	url = {http://arxiv.org/abs/2301.10092},
	doi = {10.48550/arXiv.2301.10092},
	abstract = {In this paper, we compare Model Soups performances on three different models (ResNet, ViT and EfficientNet) using three Soup Recipes (Greedy Soup Sorted, Greedy Soup Random and Uniform soup) from arXiv:2203.05482, and reproduce the results of the authors. We then introduce a new Soup Recipe called Pruned Soup. Results from the soups were better than the best individual model for the pre-trained vision transformer, but were much worst for the ResNet and the EfficientNet. Our pruned soup performed better than the uniform and greedy soups presented in the original paper. We also discuss the limitations of weight-averaging that were found during the experiments. The code for our model soup library and the experiments with different models can be found here: https://github.com/milo-sobral/ModelSoup},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Dansereau, Charles and Sobral, Milo and Bhogal, Maninder and Zalai, Mehdi},
	month = jan,
	year = {2023},
	note = {arXiv:2301.10092 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	}
